# data-collection-challenge
In this scenario I am using web-scraping skills to extract data from a website. The modules Splinter and BeautifulSoup will be used, for automated browsing and HTML parsing respectively. This challenge involves extracting information and data from two websites that analyse the planet Mars.
1. A Mars news site is scraped and its text elements are extracted, specifically the news article titles and their preview text. These are stored in a Python list and then exported into a JSON file.
2. From a Mars temperature data website, the data in the table is extracted. This data was placed into a Pandas DataFrame and then analysed. The number of Martian months, number of Martian days in the dataset, coldest and warmest months at Curiosity's location and the lowest and highest atmospheric pressure were determined. Additionally, from the temperature data, the total number of days in a Martian year were determined. Finally, the DataFrame was exported to a csv file.